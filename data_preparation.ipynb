{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import calendar\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_weather_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # keeping data only of the relevant cities (Adilabad, Nizamabad, Karimnagar, Khammam and Warangal)\n",
    "    warangal_varaints = [\"Warangal (U)\", \"Warangal (R)\", \"Warangal\", \"Warangal Rural\", \"Warangal Urban\"]\n",
    "    cities = [\"Adilabad\", \"Nizamabad\", \"Karimnagar\", \"Khammam\"]\n",
    "    \n",
    "    warangal_df = df.loc[df[\"district\"].isin(warangal_varaints)]\n",
    "    df = df.loc[df[\"district\"].isin(cities)]\n",
    "\n",
    "    # getting month out of odate attribute\n",
    "    df[\"month\"] = pd.DatetimeIndex(df[\"odate\"], dayfirst=True).month\n",
    "    df[\"month\"] = df[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
    "\n",
    "    # drop unnecessary rows\n",
    "    df.drop(columns=[\"mandal\",\"odate\"], inplace=True)\n",
    "\n",
    "    # grouping the df by district and month and getting mean values for every month\n",
    "    df = df.groupby(by=[\"district\", \"month\"]).mean().reset_index()\n",
    "\n",
    "    # doing the same operations for warangal_df\n",
    "    warangal_df[\"month\"] = pd.DatetimeIndex(warangal_df[\"odate\"], dayfirst=True).month\n",
    "    warangal_df[\"month\"] = warangal_df[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
    "    warangal_df.drop(columns=[\"mandal\", \"odate\"], inplace=True)\n",
    "    warangal_df = warangal_df.groupby(by=[\"district\", \"month\"]).mean().reset_index()\n",
    "\n",
    "    # getting mean data for warangal\n",
    "    warangal_df = warangal_df.set_index([\"district\"]).groupby(by=\"month\").mean().reset_index()\n",
    "    warangal_df[\"district\"] = \"Warangal\"\n",
    "\n",
    "    # appending warangal data back to df\n",
    "    df = df.append(warangal_df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv_weather(path: str, year: int):\n",
    "    files_list = glob.glob(path + \"/*.csv\")\n",
    "    col_names = [\"district\", \"mandal\", \"odate\", \"cumm_rainfall\", \"temp_min\", \"temp_max\", \"humidity_min\", \"humidity_max\", \"wind_speed_min\", \"wind_speed_max\"]\n",
    "    main_df = pd.read_csv(files_list[0], skiprows=1, names=col_names)\n",
    "\n",
    "    if len(files_list) != 1:\n",
    "        for i in range(1, len(files_list)):\n",
    "            data = pd.read_csv(files_list[i], skiprows=1, names=col_names)\n",
    "            main_df = pd.concat([main_df, data])\n",
    "    \n",
    "    main_df.sort_values(by=[\"district\", \"mandal\", \"odate\"], inplace=True)\n",
    "    main_df = compile_weather_data(main_df)\n",
    "    main_df.to_csv(f'./Weather_Data/monthly_weather_data_{year}.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp/ipykernel_27596/1223643251.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"month\"] = pd.DatetimeIndex(df[\"odate\"], dayfirst=True).month\n",
      "C:\\Users\\ayush\\AppData\\Local\\Temp/ipykernel_27596/1223643251.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"month\"] = df[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
      "c:\\Users\\ayush\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\ayush\\AppData\\Local\\Temp/ipykernel_27596/1223643251.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  warangal_df[\"month\"] = pd.DatetimeIndex(warangal_df[\"odate\"], dayfirst=True).month\n",
      "C:\\Users\\ayush\\AppData\\Local\\Temp/ipykernel_27596/1223643251.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  warangal_df[\"month\"] = warangal_df[\"month\"].apply(lambda x: calendar.month_abbr[x])\n"
     ]
    }
   ],
   "source": [
    "make_csv_weather('./Weather_Data/daily_weather_data_2018/', 2018)\n",
    "make_csv_weather('./Weather_Data/telangana-weather-data-2019--All-2023-02-14_1908/', 2019)\n",
    "make_csv_weather('./Weather_Data/telangana-weather-data-2020--All-2023-02-14_1908/', 2020)\n",
    "make_csv_weather('./Weather_Data/telangana-weather-data-2021-All-2023-02-14_1907/', 2021)\n",
    "make_csv_weather('./Weather_Data/telangana-weather-data-2022-All-2023-02-14_1907/', 2022)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vehicle Purchase Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv_vehicles(path: str, year):\n",
    "    files_list = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "    main_df = pd.read_csv(files_list[0], encoding='utf-8')\n",
    "    for i in range(1, len(files_list)):\n",
    "        data = pd.read_csv(files_list[i], encoding='utf-8')\n",
    "        main_df = pd.concat([main_df, data])\n",
    "    \n",
    "    main_df.sort_values(by=\"fromdate\", inplace=True)\n",
    "    main_df.to_csv(f'./Vehicle_Data/vehicle_purchase_data_{year}.csv', header=True, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_csv_vehicles(\"./Vehicle_Data/2019/\", 2019)\n",
    "make_csv_vehicles(\"./Vehicle_Data/2020/\", 2020)\n",
    "make_csv_vehicles(\"./Vehicle_Data/2021/\", 2021)\n",
    "make_csv_vehicles(\"./Vehicle_Data/2022/\", 2022)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Industrial Consumption Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_industry_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # dropping unnecessary columns\n",
    "    df.drop(columns=[\"Division\", \"SubDivision\", \"Section\", \"Area\", \"CatCode\", \"CatDesc\", \"TotServices\", \"BilledServices\"], inplace=True)\n",
    "\n",
    "    # keeping only required cities\n",
    "    df = df.loc[df[\"Circle\"].isin([\"ADILABAD\", \"NIZAMABAD\", \"KARIMNAGAR\", \"KHAMMAM\", \"WARANGAL\"])]\n",
    "\n",
    "    # grouping by district/circle and month and finding total energy consumption\n",
    "    df = df.groupby(by=[\"Circle\", \"Month\"]).sum().reset_index()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv_industry(path: str, year: int):\n",
    "    files_list = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "    main_df = pd.read_csv(files_list[0])\n",
    "    main_df[\"Month\"] = files_list[0][67:70]\n",
    "    for i in range(1, len(files_list)):\n",
    "        data = pd.read_csv(files_list[i])\n",
    "        data[\"Month\"] = files_list[i][67:70]\n",
    "        main_df = pd.concat([main_df, data])\n",
    "    \n",
    "    main_df = compile_industry_data(main_df)\n",
    "\n",
    "    main_df['Circle'] = main_df['Circle'].apply(lambda x: x.title())\n",
    "    main_df['Month'] = main_df['Month'].apply(lambda x: x.title())\n",
    "\n",
    "    main_df.to_csv(f'./Industry_Consumption/industrial_consumption_data_{year}.csv', header=[\"district\", \"month\", \"units\", \"load\"], index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_csv_industry('./Industry_Consumption/2019/', 2019)\n",
    "make_csv_industry('./Industry_Consumption/2020/', 2020)\n",
    "make_csv_industry('./Industry_Consumption/2021/', 2021)\n",
    "make_csv_industry('./Industry_Consumption/2022/', 2022)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AQI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_aqi_data(sheet_name: str) -> None:\n",
    "    df = pd.read_excel('./AQI_Data/aqi_data.xlsx', sheet_name=sheet_name, index_col=None)\n",
    "\n",
    "    # taking average of 2 monitoring stations in warangal\n",
    "    warangal_df = df.loc[df[\"Location\"].isin([\"Kuda, warangal\", \"Mee-Seva, Warangal\"])].drop(columns=\"Location\").mean()\n",
    "    warangal_df['Location'] = \"Warangal\"\n",
    "\n",
    "    df = df.loc[df[\"Location\"].isin([\"Nizamabad\", \"Adilabad\", \"Karimnagar\", \"Khammam\"])]\n",
    "    df = df.append(warangal_df, ignore_index=True)\n",
    "\n",
    "    # taking transpose of df\n",
    "    df = df.T\n",
    "\n",
    "    # making first row as the header and dropping it\n",
    "    df.columns = df.iloc[0]\n",
    "    df.drop(df.index[0], inplace=True)\n",
    "\n",
    "    # flattening 2D df to 1D with index as Location and Month\n",
    "    df = df.T.stack().reset_index()\n",
    "\n",
    "    df.to_csv(f'./AQI_Data/monthly_aqi_data_{sheet_name}.csv', header=[\"district\", \"month\", \"aqi\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_aqi_data(sheet_name=\"2017\")\n",
    "compile_aqi_data(sheet_name=\"2018\")\n",
    "compile_aqi_data(sheet_name=\"2019\")\n",
    "compile_aqi_data(sheet_name=\"2020\")\n",
    "compile_aqi_data(sheet_name=\"2021\")\n",
    "compile_aqi_data(sheet_name=\"2022\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv(path: str, data: str) -> None:\n",
    "    files_list = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "    main_df = pd.read_csv(files_list[0])\n",
    "    main_df[\"year\"] = files_list[0][-8:-4]\n",
    "    for i in range(1, len(files_list)):\n",
    "        df = pd.read_csv(files_list[i])\n",
    "        df[\"year\"] = files_list[i][-8:-4]\n",
    "\n",
    "        main_df = pd.concat([main_df, df])\n",
    "    \n",
    "    main_df.to_csv(f\"./monthly_{data}_data.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_csv(\"./AQI_Data/\", \"aqi\")\n",
    "combine_csv(\"./Industry_Consumption/\", \"industry_consumption\")\n",
    "combine_csv(\"./Weather_Data/\", \"weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0467c16d4e73dba61dcc106221b4b7c95372fa61fc6cc648ee99bca30bbaf279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
